<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>LangChain 프레임워크 활용 방안 연구  </title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.page-description {
	margin-bottom: 2em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(50, 48, 44, 1);
}
.highlight-gray {
	color: rgba(115, 114, 110, 1);
	fill: rgba(115, 114, 110, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(205, 60, 58, 1);
	fill: rgba(205, 60, 58, 1);
}
.highlight-default_background {
	color: rgba(50, 48, 44, 1);
}
.highlight-gray_background {
	background: rgba(248, 248, 247, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(248, 243, 252, 1);
}
.highlight-pink_background {
	background: rgba(252, 241, 246, 1);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(115, 114, 110, 1);
	fill: rgba(115, 114, 110, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(205, 60, 58, 1);
	fill: rgba(205, 60, 58, 1);
}
.block-color-default_background {
	color: inherit;
	fill: inherit;
}
.block-color-gray_background {
	background: rgba(248, 248, 247, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(248, 243, 252, 1);
}
.block-color-pink_background {
	background: rgba(252, 241, 246, 1);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-default { background-color: rgba(84, 72, 49, 0.08); }
.select-value-color-gray { background-color: rgba(84, 72, 49, 0.15); }
.select-value-color-brown { background-color: rgba(210, 162, 141, 0.35); }
.select-value-color-orange { background-color: rgba(224, 124, 57, 0.27); }
.select-value-color-yellow { background-color: rgba(236, 191, 66, 0.39); }
.select-value-color-green { background-color: rgba(123, 183, 129, 0.27); }
.select-value-color-blue { background-color: rgba(93, 165, 206, 0.27); }
.select-value-color-purple { background-color: rgba(168, 129, 197, 0.27); }
.select-value-color-pink { background-color: rgba(225, 136, 179, 0.27); }
.select-value-color-red { background-color: rgba(244, 171, 159, 0.4); }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="22c8004c-e856-8075-84a8-d5f78426142e" class="page sans"><header><h1 class="page-title">LangChain 프레임워크 활용 방안 연구  </h1><p class="page-description"></p></header><div class="page-body"><h2 id="22c8004c-e856-8076-b525-d06f7b42315f" class="">Lesson 1 랭체인을 활용한 LLM어플리케이션 개발</h2><p id="22c8004c-e856-8092-99d8-e5a8fe2863b3" class="">
</p><ul id="22c8004c-e856-8064-9ade-c51edfb251d9" class="bulleted-list"><li style="list-style-type:disc">LangChain 아키텍처</li></ul><ul id="22c8004c-e856-80f2-bb69-daf32810fb8e" class="bulleted-list"><li style="list-style-type:disc">가장 대표적인 LLM기반 응용프로그램 </li></ul><ul id="22c8004c-e856-8001-97fe-e9182334589b" class="bulleted-list"><li style="list-style-type:disc">Langchain 프로그래밍 예제</li></ul><ul id="22c8004c-e856-8064-93eb-c16e34ce3f3f" class="bulleted-list"><li style="list-style-type:disc">LLM 이란 무엇인가?</li></ul><hr id="22c8004c-e856-80ad-8638-e8d94d419785"/><h2 id="22c8004c-e856-8074-88da-c5d2f120ecdf" class="">1. LangChain 아키텍처</h2><p id="22c8004c-e856-8086-8356-f0c0093db2ba" class="">
</p><figure id="22c8004c-e856-80b0-a323-cff83f505244" class="image"><a href="image.png"><img style="width:720px" src="image.png"/></a></figure><p id="22c8004c-e856-80a6-861b-c378588cba0f" class="">
</p><p id="22c8004c-e856-8051-8cb9-fad093df825d" class=""><strong>LangChain 아키텍처</strong></p><p id="22c8004c-e856-8059-ac56-c90076c6f2ac" class="">Langchain을 기반으로 만들어진 LLM 애플리케이션은 다양한 유형의 입력소스(txt, PDF, docx, eml(비정형 텍스트 파일), 데이터베이스, 웹사이트, CSV, JSON, XML 문서 및 텍스트 파일)를 효과적으로 처리할 수 있다.</p><p id="22c8004c-e856-809b-b51c-c70027a27fdf" class=""><strong>주요 구성 요소:</strong></p><ul id="22c8004c-e856-804a-8210-cea3c01646ea" class="bulleted-list"><li style="list-style-type:disc"><strong>1) 문서 로더(Document Loader)</strong>: 외부 텍스트 콘텐츠를 정형화된 문서 객체로 파싱</li></ul><ul id="22c8004c-e856-80d6-b78e-caeff718070b" class="bulleted-list"><li style="list-style-type:disc"><strong>2) 텍스트 분할기(Text splitter)</strong>: 원시 텍스트를 원본 텍스트보다 더 쉽게 처리할 수 있는 청크(chunks)라고 불리는 작은 문서 목록으로 분할하는 역할.</li></ul><ul id="22c8004c-e856-801b-903d-faee1a6a7fc6" class="bulleted-list"><li style="list-style-type:disc"><strong>3) 임베딩 모델(Embedding Model)</strong>: 청크를 기본 정보의 의미론적 의미를 나타내는 벡터로 변환함</li></ul><ul id="22c8004c-e856-8082-9a36-cafe980e86f6" class="bulleted-list"><li style="list-style-type:disc"><strong>4) 벡터 저장소 클라이언트 (Vector storage client)</strong>: 임베딩된 벡터를 저장</li></ul><ul id="22c8004c-e856-80a0-bf9d-d16b36e41ee1" class="bulleted-list"><li style="list-style-type:disc"><strong>5) 검색기(Retriever)</strong>: 벡터 저장소나 지식 그래프 데이터베이스에서 관련 청크를 검색</li></ul><ul id="22c8004c-e856-80d0-9b80-d7b5553700df" class="bulleted-list"><li style="list-style-type:disc"><strong>6) 프롬프트(prompt)</strong>: LLM에 묻는 질문과 벡터 저장소나 지식 그래프 데이터베이스에서 검색한 청크로 표현된 컨텍스트를 캡슐화 함.</li></ul><ul id="22c8004c-e856-80e7-a5e6-ff4c8e6ed806" class="bulleted-list"><li style="list-style-type:disc"><strong>7) LLM 캐시(LLM cache)</strong>: 결과를 캐싱한다</li></ul><ul id="22c8004c-e856-8074-bf12-db9e678464a3" class="bulleted-list"><li style="list-style-type:disc"><strong>8) LLM 클라이언트(LLM client)</strong>: 대규모 언어 모델(LLM) 또는 채팅 모델과 통신</li></ul><ul id="22c8004c-e856-807d-b4a2-fe53c467ad8c" class="bulleted-list"><li style="list-style-type:disc"><strong>9) 출력 파서(Output parser)</strong>: LLM 응답을 문자열, CSV, JSON과 같은 원하는 형식으로 변환</li></ul><ul id="22c8004c-e856-804a-91c7-c0d17781d32b" class="bulleted-list"><li style="list-style-type:disc"><strong>10) 체인 (Chain)</strong>: LangChain의 처리 워크플로우를 안내하는 복합적인 구성으로, 특정 사용 사례에 맞게 사용자 정의되며 앞서 설명한 구성 요소들의 순차적 배열을 기반으로 작동함</li></ul><ul id="22c8004c-e856-808e-a5cc-e64067621e01" class="bulleted-list"><li style="list-style-type:disc"><strong>11) 에이전트 (Agent): </strong>이 구성 요소는 순차적 체인을 확장하여 동적 워크플로우를 관리한다. 에이전트의 처리 과정은 유연하며 사용자 입력이나 구성 요소 출력에 따라 유연하게 적응할 수 있다. 동적 워크플로우에서 사용되는 리소스는 대부분의 프레임워크 문서에서 &quot;도구(tools)&quot; 또는 &quot;플러그인(plugins)&quot;이라고 불리며, 모든 도구의 모음을 &quot;도구 모음(toolkit)&quot;이라고 한다.</li></ul><h2 id="22c8004c-e856-8030-ae72-cb61b9c68e5c" class="">2. 가장 대표적인 LLM기반 응용프로그램 </h2><p id="22c8004c-e856-80f6-8a4f-ce6e89995646" class="">LangChain의 포괄적인 설계는 세 가지 주요 솔루션을 가능하게 한다 - <strong>1) Summarization/query engine, 2) chatbot, and 3) Knowledge agent</strong></p><h3 id="22c8004c-e856-8016-a68d-cd206f5ce584" class="">2-1. Summarization/query engine</h3><p id="22c8004c-e856-80b9-8696-c98051ae4974" class="">LLM 기반 엔진은 다양한 컴퓨터 시스템을 위한 백엔드 도구로 작동하며, LLM에 대한 특정 요청을 처리한다. 예를 들어, 긴 텍스트 구절을 간결한 요약으로 압축하는 요약 엔진으로 기능할 수 있다. 이러한 요약은 즉시 클라이언트에게 반환 되거나 다른 애플리케이션이 사용할 수 있도록 데이터베이스에 저장될 수 있으며, 이는 아래 그림에 잘 요약돼 있다.</p><figure id="22c8004c-e856-802d-b2ce-e881888e05c4" class="image"><a href="image%201.png"><img style="width:709.9802856445312px" src="image%201.png"/></a></figure><p id="22c8004c-e856-80c1-8cdc-d463ab85f3b0" class=""><strong>LLM 서비스 기반 요약 엔진 Workflow 설명</strong></p><p id="22c8004c-e856-80fa-a0fd-dde0d128c61b" class="">   1) 클라이언트 시스템이 요약 엔진에 문서를 전달함</p><p id="22c8004c-e856-8081-b6e6-f6d3411fd97f" class="">   2) 엔진이 프롬프트를 통해 LLM에 문서를 전송함</p><p id="22c8004c-e856-8032-9b4d-e382e7896187" class="">   3) 요약된 문서</p><p id="22c8004c-e856-8079-b94a-e7d95a665d09" class="">   4) 엔진이 요약된 문서를 저장함</p><p id="22c8004c-e856-80e2-9c5f-dc148b446a3c" class="">   5) 엔진이 요약된 문서를 반환함</p><p id="22c8004c-e856-805c-8c5d-da208516ace5" class="">
</p><h3 id="22c8004c-e856-8092-91ee-d677877b932a" class="">2-2. LLM-based Chatbots</h3><p id="22c8004c-e856-80a4-b74b-f85a2d1442dd" class="">다양한 유형의 챗봇들은 다음과 같은 일반적인 작업에 특화되어 있다: 텍스트 요약, 질문 답변, 언어 번역. 챗봇은 이미 가지고 있는 지식(예: 벡터 저장소에 위치한)을 사용하거나 사용자 인터페이스를 통해 입력을 받아 작업을 수행하는 데 도움을 준다.</p><figure id="22c8004c-e856-8036-9d94-debbf9c33614" class="image"><a href="image%202.png"><img style="width:709.9661865234375px" src="image%202.png"/></a></figure><ol type="1" id="22c8004c-e856-80c2-bd48-c5a4b1903c2b" class="numbered-list" start="1"><li>사용자가 챗봇 REST API로 문서를 제출</li></ol><ol type="1" id="22c8004c-e856-80ca-b920-e32b5c08e7ba" class="numbered-list" start="2"><li>챗봇이 프롬프트를 통해 LLM에 문서를 전송</li></ol><ol type="1" id="22c8004c-e856-80fe-823d-d709b667d4c4" class="numbered-list" start="3"><li>요약된 문서</li></ol><ol type="1" id="22c8004c-e856-8075-9e80-c385c0de83a1" class="numbered-list" start="4"><li>엔진이 요약된 문서를 반환</li></ol><p id="22c8004c-e856-80ac-bec0-c0743e8d6791" class="">요약 챗봇은 요약 엔진과 몇 가지 유사한 점이 있지만, LLM과 사용자가 함께 결과를 미세조정하고 개선할 수 있는 대화형(상호작용) 경험을 제공한다. </p><h3 id="22c8004c-e856-807e-ac41-fad293e83598" class="">2-3. LLM-based autonomous agents</h3><p id="22c8004c-e856-8082-be3b-d4c800eba186" class="">LLM 기반 자율 에이전트는 다양한 데이터 소스와 분기 워크플로우(Branching workflow)를 다룰 때 LLM과 협력하여 복잡한 워크플로우를 처리하도록 설계된 정교한 도구다.</p><p id="22c8004c-e856-80c5-8eb4-ec42d052617e" class="">이 자율 에이전트는 다양한 구조화된 데이터 소스와 비구조화된 데이터 소스에 연결하여 복잡한 작업을 수행하도록 설계되었다. LLM과 상호작용할 때 워크플로우의 각 단계에서 높은 수준의 독립성을 보여주며, 최종적으로 포괄적인 결과를 제공할 수 있다. </p><p id="22c8004c-e856-805d-a8f6-d88bb4097b7b" class="">예를 들어, 여행사가 외부 클라이언트 시스템(예: agoda, 야놀자 등)에서 오는 자연어 요청을 기반으로 휴일 패키지를 만들기 위해 자율 에이전트를 사용하는 시나리오늘 생각해보자. 아래 그림에 나온 것처럼, 자율 에이전트는 LLM에 프롬프트를 보내 요청에 맞는 도구(예: 항공, 호텔, 렌터카 제공업체, 날씨 예보 서비스, 내부 휴일 할인 데이터베이스)를 선택하도록 요청할 수 있다. <mark class="highlight-pink"><mark class="highlight-pink_background">LLM은 개발자가 잘 설계한 프롬프트에 따라 관련 도구를 선택하고</mark></mark>, 휴일 할인 데이터베이스용 SQL 쿼리나 제공 업체용 REST API 요청 같은 필요한 쿼리를 생성한다. 에이전트는 각 쿼리를 실행하고 결과를 수집한 뒤, 원래 휴일 요청과 쿼리된 모든 도구의 결과를 포함한 컨텍스트와 함께 LLM에 또 다른 프롬프트를 보낸다. LLM은 모든 예약을 포함한 요약된 휴일 계획으로 응답하고, 에이전트는 이를 외부 클라이언트 시스템에 반환할 수 있다.</p><figure id="22c8004c-e856-8070-b802-d0adaf446692" class="image"><a href="image%203.png"><img style="width:700.7882690429688px" src="image%203.png"/></a></figure><p id="22c8004c-e856-8076-b217-cbc8dbb5cc99" class="">
</p><p id="22c8004c-e856-8094-93c6-c94b02007b1c" class="">실제 어플리케이션에서의 워크플로우는 위 그림보다 더 복잡할 수 있다. 예를 들어, 최종 휴일 계획이 생성되기 전에 에이전트와 LLM간에 여러 번의 Loop을 통한 미세조정이 필요할 수도 있으며, 금융이나 의료 군사 등과 같은 중요한 응용 분야에서는 에이전트에 “사람의 개입(Human-in-the loop )” 단계를 포함할 수도있다.    </p><h2 id="22c8004c-e856-8047-8d19-e8750758a27f" class="">3. Langchain 프로그래밍 예제</h2><h3 id="22c8004c-e856-8046-b930-f03efda83d01" class="">3-1. 문장 완성 예시 (sentence completion)</h3><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="22c8004c-e856-8030-8234-e8424839a4d7" class="code"><code class="language-Python">from langchain_openai import ChatOpenAI
import getpass

OPENAI_API_KEY = getpass.getpass(&#x27;Enter your OPENAI_API_KEY&#x27;)

llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, 
                 model_name=&quot;gpt-4o-mini&quot;)

llm.invoke(&quot;It&#x27;s a hot day, I would like to go to the…&quot;)</code></pre><p id="22c8004c-e856-80f8-9307-f9d5dc3a1abd" class="">
</p><p id="22c8004c-e856-8076-ba84-f22a3b4d3a43" class="">위 명령어를 입력하면 아래와 같은 출력값을 볼 수 있다. </p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="22c8004c-e856-80bf-9070-cc12ec42a082" class="code"><code class="language-Python">AIMessage(content=&quot;…beach to cool off and relax in the refreshing water. The sound of
the waves crashing against the shore and the feeling of the warm sand beneath my feet is
exactly what I need to unwind and escape from the heat.&quot;, response_metadata=
{&#x27;finish_reason&#x27;: &#x27;stop&#x27;, &#x27;logprobs&#x27;: None})</code></pre><h3 id="22c8004c-e856-804a-8bef-de9fa39c7256" class="">3-1. Prompt Engineering 예시</h3><p id="22c8004c-e856-80b8-8edf-d6e850951bcd" class="">프롬프트는 LLM에게 작업을 수행하고 응답을 생성하도록 지시하는 명령을 의미한다. 이는 LLM 응용 프로그램의 핵심 부분으로, LLM 응용 프로그램 개발 시 종종 시행착오를 통해 프롬프트를 설계하고 다듬는 데 많은 시간을 투자한다. 프롬프트를 둘러싼 다양한 패턴과 기술이 이미 형성되고 있으며, 이를 통해 프롬프트 엔지니어링이라는 학문이 등장하고 있다. 이 분야는 최상의 답변을 얻을 수 있는 프롬프트를 만드는 데 초점을 맞춘다.</p><p id="22c8004c-e856-809d-966d-e177fec3a5c7" class="">
</p><p id="22c8004c-e856-80c0-8576-f54f4e20d8f2" class="">가장 간단한 프롬프트 예시는 다음과 같다. </p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="22c8004c-e856-8034-9546-e79e8b96226a" class="code"><code class="language-Python">prompt_input = &quot;&quot;&quot;Write a short message to remind users to be
vigilant about phishing attacks.&quot;&quot;&quot;
response = llm.invoke(prompt_input)
print(response.content)</code></pre><p id="22c8004c-e856-8079-8cf3-ef36b8778673" class="">결과:</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="22c8004c-e856-804a-afde-f2155bd87be0" class="code"><code class="language-Python">Just a friendly reminder to stay vigilant against phishing attacks. Be cautious of any
suspicious emails, messages, or requests for personal information. Stay safe online!</code></pre><h3 id="22c8004c-e856-8007-87cb-f781ccc6936a" class="">3-2. Prompt 템플릿 예시</h3><p id="22c8004c-e856-8035-a4c7-e549b0d637dd" class="">프롬프트 템플릿은 같은 주제의 다양한 버전을 실행할 수 있도록 구조화된 프롬프트를 의미한다. LangChain은 이를 위해 PromptTemplate이라는 클래스를 제공한다. 이 클래스의 역할은 템플릿 구조(template structure)와 입력 매개변수(input parameters)를 이용하여 프롬프트를 생성하는 것이다. 아래는 템플릿에서 프롬프트를  생성하고 실행하는 예제이다. </p><p id="22c8004c-e856-807c-ae86-dd5a9d33b723" class="">  </p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="22c8004c-e856-80c4-8bba-e53f06b1b675" class="code"><code class="language-Python">from langchain_core.prompts import PromptTemplate

segovia_aqueduct_text = &quot;&quot;&quot;The Aqueduct of Segovia (Spanish: Acueducto de Segovia) is a
Roman aqueduct in Segovia, Spain. It was built around the first century AD to channel
water from springs in the mountains 17 kilometres (11 mi) away to the city&#x27;s fountains,
public baths and private houses, and was in use until 1973. Its elevated section, with
its complete arcade of 167 ....&quot;&quot;&quot;

prompt_template = PromptTemplate.from_template(&quot;You are an experienced copywriter. 
Write a {num_words} summary of the following text, using a {tone} tone:{text}&quot;)

prompt_input = prompt_template.format(
    text=segovia_aqueduct_text,
    num_words=20,
    tone=&quot;knowledgeable and engaging&quot;)

response = llm.invoke(prompt_input)
print(response.content)    </code></pre><p id="22c8004c-e856-8036-aacf-cbffe621baba" class="">위 코드를 실행하면 다믕과 유사한 결과가 나온다:</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="22c8004c-e856-8024-8ba5-c9723cdb6adf" class="code"><code class="language-Python">The Aqueduct of Segovia, a Roman marvel in Spain, dates back to the 1st century AD,
channeling water for centuries.</code></pre><h3 id="22c8004c-e856-805f-8bba-c7143bcc8f46" class="">3-3. LangChain의 LCEL(LangChain Expression Language) Chain 기능을 활용한 코드 실행 </h3><p id="22c8004c-e856-80a6-af5e-e1a3be8c7fcc" class="">LangChain을 사용하는 이점 중 하나는 &quot;체인(chain)&quot;이라는 개념을 중심으로 구축된 처리 기술이다. 체인은 특정 결과를 달성하기 위해 구성 요소들을 연결한 파이프라인이다. 예를 들어, (이 코드 조각을 실행하지는 말고) 웹사이트에서 최신 뉴스를 스크랩하고, 이를 요약한 뒤, 누군가에게 이메일로 보내는 체인을 다음과 같이 만들 수 있다:</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="22c8004c-e856-80a5-af95-f09c710310f8" class="code"><code class="language-Python">chain = web_scraping | prompt | llm_mode | email_text</code></pre><p id="22c8004c-e856-8060-918e-f602b7330873" class="">
</p><p id="22c8004c-e856-80a5-b919-c150c8b697a4" class="">다음은 LCEL을 활용한 또다른 코드 예시이다:</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="22c8004c-e856-801d-a34d-f5221faec4ba" class="code"><code class="language-Python">prompt_template = PromptTempalte.from_template(&quot;You are an experienced copywriter. 
Write a {num_words} words summary of the following text, using a {tone} tone: {text}&quot;

llm = ChatOpenAI(openai_api_key = OPENAI_API_KEY, model_name=&quot;gpt-4o-mini&quot;

chain = prompt_template | llm

response = chain.invoke({&quot;text&quot;: segovia_aqueduct_text, 
                         &quot;num_words&quot;: 20,
                         &quot;tone&quot;: &quot;knowledgeable and engaging&quot;})
print(response.content)</code></pre><p id="22c8004c-e856-80b6-8a32-d227ed61ece4" class="">위 코드 실행 시 다음과 같은 결과 값을 얻을 수 있다. </p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="22c8004c-e856-802d-8277-c9204846b8af" class="code"><code class="language-Python">The Aqueduct of Segovia: A Roman marvel channeling water to the city, adorned with 167
arches, symbolizing Segovia&#x27;s rich history.</code></pre><h2 id="22c8004c-e856-8076-ae3c-c5bbbf70388c" class="">4. LLM(Large Language Model)이란 무엇인가?</h2><p id="22c8004c-e856-80e3-9bc3-cf46eb4c2aaf" class="">   대규모 언어 모델(LLM)은 인간 언어와 관련된 작업, 예를 들어 텍스트 이해, 생성, 요약, 번역 등을 위해 설계된 딥러닝 신경망이다. LLM은 기사, 책, 소셜 미디어, 웹사이트 같은 소스에서 얻은 엄청난 양의 텍스트 데이터로 훈련된다. 이 모델들은 언어를 &quot;토큰&quot;이라는 단위로 처리하는데, 토큰은 대략 단어와 비슷하지만 일부 단어는 여러 토큰으로 나뉠 수도 있다. 가장 큰 LLM은 수조 개의 토큰으로 훈련돼서 인간 언어 능력을 흉내낼 수 있다.이런 광범위한 훈련 덕분에 LLM은 문법, 문장 구조, 맥락을 잘 이해한다. 인간처럼 텍스트를 해석하고 생성할 수 있어서 &quot;생성형 AI&quot;로 분류된다. (이 카테고리에는 오디오나 비디오 같은 콘텐츠를 만드는 기술도 포함된다.) 예를 들어, LLM은 원시 제품 데이터를 바탕으로 온라인 상점의 제품 설명을 자동으로 만들어낼 수 있다. LLM은 자연어 기능을 애플리케이션에 탑재하여 사용자 상호작용을 더 매끄럽게 할 수 있다. 사용자는 &quot;프롬프트(prompt)&quot;를 통해 LLM과 상호작용하는데, 프롬프트에는 작업에 대한 &quot;지시(instruction)&quot;와 작업을 이해하는데 필요한 텍스트인 &quot;맥락(context)&quot;이 포함된다. 프롬프트는 채팅 대화 형식일 수도 있고, REST API를 통해 프로그램적으로 전달될 수도 있다.</p><p id="22c8004c-e856-8089-8e14-f3fa7c2ccf49" class="">   LLM은 문장에서 다음 단어나 토큰을 계속 예측하도록 설계되었다. LLM은 프롬프트가 주어지면 이를 분석해서 이전에 예측한 단어들을 고려하며 다음 단어를 예측할 수 있다. 예를 들어, &quot;It’s a hot day, I would like to go to the,&quot;라는 입력이 있으면 LLM은 다음 단어로 &quot;beach&quot;을 예측할 수 있는데, 이를 기술적으로 &quot;완성(completion)&quot;이라고 부른다.</p><p id="22c8004c-e856-807f-bb07-c48de8be191e" class="">   LLM은 훨씬 더 인상적이고 다양한 작업을 처리할 수 있다. 주어진 문장에서 다음 단어를 예측하는 것을 넘어, 최소한의 초기 입력만으로 전체 문장, 단락, 심지어 긴 에세이나 소설까지 작성할 수 있다. 이는 주어진 프롬프트와 이전 출력에 기반해 텍스트를 계속 생성함으로써 이루어진다. LLM이 문장에서 다음 단어를 예측하고 단락이나 에세이 같은 전체 텍스트를 생성하는 놀라운 능력은 &quot;트랜스포머 구조&quot;에 그 뿌리를 두고 있다. 이 구조는 2017년 구글 브레인 팀, 구글 리서치, 그리고 토론토 대학교가 &quot;Attention is All You Need&quot;라는  논문<a href="https://arxiv.org/pdf/1706.03762.pdf">(https://arxiv.org/pdf/1706.03762.pdf)</a>에서 소개했다. 이 구조는 단어들이 서로 어떻게 관련되는지를 세심하게 분석하며 언어 이해를 깊이 탐구한다. 구글 브레인의 논문에 나오는 아래 그림은 트랜스포머가 어떻게 작동하는지 개략적으로 보여준다.  </p><figure id="22c8004c-e856-8022-9a97-cfb273127d8c" class="image"><a href="image%204.png"><img style="width:709.9661865234375px" src="image%204.png"/></a></figure><p id="22c8004c-e856-803d-9c77-e33f6ae49201" class="">위 그림에서 설명된 Transformer 아키텍처의 작동 원리는 간략하게 다음과 같다. </p><p id="22c8004c-e856-8085-a0ea-cb8873d21ef3" class="">LLM은 일반적으로 인코더와 디코더라는 두 가지 주요 구성 요소를 가진다(단, GPT 계열 같은 일부 모델은 디코더만 사용한다). 인코더는 입력 텍스트를 &quot;임베딩&quot;이라는 벡터로 변환하는데, 이는 단어의 의미와 맥락을 포착한다. 이 임베딩에는 각 단어나 토큰의 위치 및 맥락적 세부 정보가 포함된다. 디코더는 인코더의 임베딩과 이전 단어들을 사용해 시퀀스의 다음 단어를 예측함으로써 출력을 생성한다. &quot;어텐션&quot; 메커니즘은 모델이 입력과 출력의 핵심 부분에 집중하도록 도와주며, 텍스트에서 단어들이 멀리 떨어져 있더라도 그들 간의 관계를 이해할 수 있게 한다. <mark class="highlight-teal_background">작동 원리에 대한 더 자세한 설명은 나중에 하도록 하겠다. 여기서는 기본 작동 원리 정도만 간략하게 이해하고 넘어가도 된다. </mark></p><h3 id="22c8004c-e856-802d-9641-ca7d4564e872" class="">4-1. LLM은 주로 어떻게 사용되는가?</h3><p id="22c8004c-e856-8071-b939-d52d4e171747" class=""> LLM은 텍스트 분류, 코드 생성, 논리적 추론과 같은 다양한 작업에 사용된다. 다음은 가장 일반적인 실제 사용 사례들이다:</p><ul id="22c8004c-e856-8069-a50d-f6b81fbfe13d" class="bulleted-list"><li style="list-style-type:disc"><strong>텍스트 분류 및 감정 분석(Text classification &amp; Sentiment analysis)</strong>: LLM은 뉴스 기사를 카테고리로 분류하거나 감정 분석을 기반으로 주식을 추천하는 등의 기능을 수행할 수 있다. </li></ul><ul id="22c8004c-e856-80a7-8a91-e644a441001a" class="bulleted-list"><li style="list-style-type:disc"><strong>자연어 이해 및 생성(Natural language understanding ad generation)</strong>: LLM은 텍스트의 주요 주제를 파악하거나 길이, 톤, 용어 선호도에 따라 요약을 생성할 수 있다. Duolingo는 AI를 사용해 수업 준비 시간을 혁신적으로 단축하고 있으며 관련 내용은 블로그 포스트 “How Duolingo Uses AI to Create Lessons Faster”에 자세히 설명되어 있다.</li></ul><ul id="22c8004c-e856-802c-94b2-c42460b7ab0d" class="bulleted-list"><li style="list-style-type:disc"><strong>의미검색(semantic search)</strong>: LLM은 단순 키워드가 아닌 질문의 맥락과 의도를 사용해 데이터베이스를 조회할 수 있다. Picnic 슈퍼마켓 앱은 레시피 검색을 개선하기 위해 LLM을 사용하며, 이는 Medium 포스트 “Enhancing Search Retrieval with Large Language Models (LLMs)”에 설명되어 있다.</li></ul><ul id="22c8004c-e856-802b-944c-d96305af70c0" class="bulleted-list"><li style="list-style-type:disc"><strong>자율추론 및 워크플로우 실행(Autonomous reasoning and workflow execution)</strong>: LLM은 사용자의 요청을 이해하고 워크플로우 전반에 걸쳐 입력과 출력을 처리해 완전한 휴가 패키지 계획/개발과 같은 작업을 효과적으로 처리할 수 있다(2-3 LLM-based autonomous agents 참고).</li></ul><ul id="22c8004c-e856-807b-b85a-e835170b2619" class="bulleted-list"><li style="list-style-type:disc"><strong>구조화된 데이터 추출(Structured data extraction)</strong>: LLM은 뉴스 기사나 재무 보고서에서 엔터티와 그 관계를 추출하는 등의 비정형 텍스트에서 구조화된 데이터를 추출할 수 있다.</li></ul><ul id="22c8004c-e856-803c-bc05-eab09fab918b" class="bulleted-list"><li style="list-style-type:disc"><strong>코드 이해 및 생성(Code understanding and generation)</strong>: LLM은 프로그래머가 작성한 코드에서 문제를 발견하거나, 사용자의 지시에 따라 함수, 클래스, 심지어 전체 애플리케이션을 생성하는 등의 작업에도 활용될 수 있다.    </li></ul><h3 id="22c8004c-e856-8059-981b-c0daaed00605" class="">4-2. LLM을 사용자의 필요/요구에 맞춰 조정하는 방법</h3><p id="22c8004c-e856-80aa-af40-c06fbcc6dd59" class="">LLM은 특정 도메인에 대한 사전 지식이나 추가 훈련 없이도 사용자의 요청과 의도에 맞춰 응답하는 능력을 향상시킬 수 있는 몇가지 핵심 기술들을 가지고 있다. 여기에는 주로 다음 기술들이 포함된다: </p><p id="22c8004c-e856-805c-aa36-da0e559c1d2f" class="">
</p><ul id="22c8004c-e856-801a-a256-d4e90b1e9cfa" class="bulleted-list"><li style="list-style-type:disc">Prompt Engineering</li></ul><ul id="22c8004c-e856-803d-9dbe-da84c2a3cade" class="bulleted-list"><li style="list-style-type:disc">Retrieval Augmented Generation (RAG)</li></ul><ul id="22c8004c-e856-80d2-bc29-c748fff36cdf" class="bulleted-list"><li style="list-style-type:disc">Fine-tuning</li></ul><p id="22c8004c-e856-809a-93c5-c3d9facad54f" class="">
</p><p id="22c8004c-e856-8034-a65e-f80721f6221b" class=""><mark class="highlight-pink"><strong>Prompt Engineering</strong></mark>: </p><p id="22c8004c-e856-8058-94e9-f41307efcb6e" class="">   LLM에 주어지는 프롬프트는 간단한 요청부터 추가 데이터나 맥락이 포함된 복잡한 지시까지 다양하다. 프롬프트 엔지니어링은 LLM이 사용자의 의도를 효과적으로 이해하고 응답할 수 있도록 하는데 그 목적이 있다. 이 기법을 활용하면 LLM은 추가적인 훈련 없이도 특정 분야나 도메인에 관련된 사용자의 지시를 효과적으로 이해하고 처리할 수 있으며, 이는 흔히 &quot;<mark class="highlight-red">I</mark><mark class="highlight-red"><strong>n-context learning</strong></mark>&quot; 기술로 알려져 있다. </p><p id="22c8004c-e856-8051-8f23-fed83f674687" class="">   프롬프트 엔지니어링은 종종 특정 작업에 맞춘 지시와 맥락이 포함된 프롬프트 템플릿을 설계하는 것을 포함한다. 이 템플릿은 고정된 지시와 재사용을 위해 사용자 정의 가능한 맥락 매개변수로 표준화 할 수 있다. 이 방법의 단순성과 효율성은 LLM이 낯선 주제에서도 관련성 있는 응답을 제공할 수 있도록 도움을 준다. 맞춤형 챗봇은 대화 기록을 통해 대화 맥락을 유지함으로써 상호작용을 개선하기 위해 이러한 기법들을 활용한다. 그러나 프롬프트 엔지니어링만으로는 사용자가 콘텐츠나 엔터프라이즈 데이터와 상호작용해야 할 때 애플리케이션에 필요한 기능을 충분히 제공하지 못하는 경우가 많다. 이런 경우 우리는 검색증강생성 기법으로 알려진 RAG 아키텍처를 사용하는 것을 고려할 수 있다.</p><p id="22c8004c-e856-8026-a349-fe1db343a354" class=""><mark class="highlight-pink"><strong>Retrieval Augemnted Generation</strong></mark>: </p><p id="22c8004c-e856-8021-9a11-c67df3fd3f92" class="">LangChain은 임베딩과 원문 텍스트 조각을 벡터 스토어(vector store)에 저장하여, 빠른 정보 검색을 위한 지식 데이터베이스를 생성하고 활용할 수 있다. 사용자가 자연어로 벡터 데이터베이스에 질문을 하면, LangChain Retriever가 질문을 임베딩으로 변환해 저장된 임베딩과 비교하고 가장 유사한 텍스트 조각을 검색한다. 그 후 리트리버는 가장 유사한 임베딩과 해당 텍스트 조각만 반환한다. 이렇게 로컬 지식 베이스를 활용하면 가장 관련성이 높은 텍스트만 검색되어 LLM에 전송되므로 맥락의 양(context-window)을 크게 줄일 수 있는 이점이 있다. 이는 LLM의 성능을 향상 시킬 뿐 아니라, 많은 LLM이 처리된 토큰 수에 따라 요금을 부과하므로 비용 또한 절감할 수 있다.마지막으로, RAG를 활용한 로컬 지식 베이스를 활용하면 LLM 응답이 검증된 소스에 기반을 두므로, &quot;환각(hallucination)&quot;이나 부정확한 응답을 최소화할 수 있다. </p><p id="22c8004c-e856-8040-9da7-c0af87323d40" class=""><mark class="highlight-pink"><strong>Fine-tuning</strong></mark>: </p><p id="22c8004c-e856-80df-82c9-d9f8da06624f" class="">파인튜닝은 사전 훈련된 LLM을 특정 작업에 특화되도록 조정하는 과정이다. 이는 모델을 특정 기능을 처리하는 방법을 가르치는 예제 데이터셋으로 훈련시키는 과정을 포함한다. 과거에는 전문 프로그래밍 라이브러리를 사용해야만 수행할 수 있지만, 이제는 데이터셋과 최소한의 설정 만으로 파인튜닝을 가능하게 하는 &quot;제로 코드&quot; 또는 &quot;로우 코드&quot; 도구가 많다. </p><p id="22c8004c-e856-8095-9d7b-c8c5a62557b5" class="">파인튜닝의 장점은 LLM에 도메인별 지식을 부여해 전문화된 프롬프트를 반복적으로 제공할 필요를 줄일 수 있다는 것이다. 하지만 데이터셋을 준비하고 정제하는 데 시간이 많이 걸리고, 고성능 GPU를 구매하거나 대여하는 데 비용이 많이 든다는 단점도 있다 .파인튜닝의 필요성에 대해서는 여러 논란이 있다. 일부 전문가는 일반 LLM이 추가 훈련 없이도 다양한 도메인에서 효과적이라고 믿는다. 하지만 고유한 전문 용어가 필요한 특화된 분야에서는 파인튜닝이 필수적이라고 주장하는 학자들도 있다. </p><p id="22c8004c-e856-80ae-96c4-faa753f0410b" class="">파인튜닝된 모델의 예로는 생물학을 위한 BioMistral, 법률을 위한 LexisNexis LLM, 금융을 위한 BloombergGPT, 프로그래밍을 위한 CodeGPT 등이 있다. Heydar Soudani, Evangelos Kanoulas, Faegheh Hasibi와 같은 연구자들은 &quot;Fine-Tuning vs. Retrieval-Augmented Generation for Less Popular Knowledge&quot; 논문에서 검색 증강 생성(RAG)이 파인튜닝보다 더 효과적일 수 있다고 주장하기도 한다. RAG는 프롬프트를 사용해 모델에 지식을 제공하며, 사전 훈련된 모델과 프롬프트 엔지니어링을 활용해 정확도를 높이고 비용을 줄일 수 있다. 요약하자면, 파인튜닝은 LLM을 특정 도메인에 맞춰 성능을 개선하는 역할을 한다. 그 중요성은 도메인 용어의 복잡성에 따라 다르다고 할 수 있다. 개발자는 효과적인 이해와 응답 생성에 초점을 맞춰 파인튜닝의 필요성에 대해 판단할 필요가 있다. </p></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span></body></html>